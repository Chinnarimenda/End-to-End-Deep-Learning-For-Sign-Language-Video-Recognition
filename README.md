# ğŸ¤Ÿ Sign Language Video Recognition using Deep Learning

This repository contains the source code, documentation, and resources for the major project titled **"Language Translation: End-to-End Deep Learning for Sign Language Video Recognition"**, submitted by **M. Chinnari (21C91A6637)** in partial fulfillment of the B.Tech degree in **Computer Science and Engineering (Artificial Intelligence & Machine Learning)** at **Holy Mary Institute of Technology & Science**.

## ğŸ“Œ Project Overview

This project aims to develop a real-time system that translates Indian Sign Language (ISL) gestures into text using deep learning. It leverages Convolutional Neural Networks (CNNs) and transfer learning to recognize hand gestures from video input, promoting inclusive communication for the deaf and hard-of-hearing community.

## ğŸ¯ Objectives

- Build an end-to-end deep learning model for sign language recognition.
- Use webcam input to capture and classify ISL gestures.
- Apply CNNs and LSTMs to extract spatial and temporal features.
- Ensure high accuracy even with limited datasets.
- Promote accessibility and inclusion through AI.

## ğŸ§  Technologies Used

- Python
- TensorFlow / Keras
- OpenCV
- NumPy / Pandas
- CNN + LSTM architecture
- Webcam or Microsoft Kinect (optional)

## ğŸ“ Repository Structure
sign-language-recognition/ 

â”œâ”€â”€ dataset/ # ISL gesture images or video samples 

â”œâ”€â”€ models/ # Trained model files (.h5)

â”œâ”€â”€ src/ # Source code for training and inference â”‚

â”œâ”€â”€ data_preprocessing.py â”‚

â”œâ”€â”€ train_model.py â”‚

â”œâ”€â”€ predict_sign.py â”‚

â””â”€â”€ webcam_inference.py 

â”œâ”€â”€ snapshots/ # Screenshots of model predictions

â”œâ”€â”€ requirements.txt # Python dependencies 

â”œâ”€â”€ README.md # Project overview 

â””â”€â”€ LICENSE # Open-source license

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/sign-language-recognition.git
   cd sign-language-recognition

pip install -r requirements.txt

python src/webcam_inference.py

ğŸ“¸ Sample Output
Input: ISL gesture for "HOW OLD YOU"
Output: "How old are you?"





























